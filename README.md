# Note Summarizer

A full-stack note summarization web application with a React/TypeScript frontend and GPU-accelerated ML backend via Modal.

![Note Summarizer](generated-icon.png)

## üöÄ Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Vercel                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Static Frontend   ‚îÇ    ‚îÇ   Serverless API Functions   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   (React + Vite)    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   /api/summarize             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                     ‚îÇ    ‚îÇ   /api/health                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                       ‚îÇ
                                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Modal                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   GPU-Accelerated Python Functions                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - BART-large-CNN Summarization Model                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Sentence-based Text Chunking                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - T4 GPU for Fast Inference                            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ‚ú® Features

- **Document Upload**: Drag-and-drop interface for TXT, PDF, and DOCX files
- **Word Count Validation**: Maximum 2000 words per document
- **Customizable Parameters**: Adjust chunk length and overlap for summarization
- **Loading Animation**: Beautiful loading page with rotating status messages
- **Summary Display**: View, copy, and download generated summaries
- **Google Gemini-Inspired Design**: Clean, modern UI with dark/light mode support

## üì¶ Project Structure

```
NoteSummarizer/
‚îú‚îÄ‚îÄ api/                    # Vercel serverless functions
‚îÇ   ‚îú‚îÄ‚îÄ summarize.ts        # Main summarization endpoint
‚îÇ   ‚îî‚îÄ‚îÄ health.ts           # Health check endpoint
‚îú‚îÄ‚îÄ client/                 # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/          # Page components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ landing.tsx # Upload page
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loading.tsx # Processing page
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary.tsx # Results page
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/     # Reusable UI components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.tsx         # Main router
‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ modal_backend/          # Modal ML backend
‚îÇ   ‚îú‚îÄ‚îÄ app.py              # Modal app with BART model
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt    # Python dependencies
‚îú‚îÄ‚îÄ shared/                 # Shared TypeScript types
‚îú‚îÄ‚îÄ vercel.json             # Vercel configuration
‚îî‚îÄ‚îÄ package.json
```

## üõ†Ô∏è Local Development

### Prerequisites

- Node.js 18+
- Python 3.11+ (for local ML testing)
- Modal CLI (for deploying ML backend)

### Install Dependencies

```bash
npm install
```

### Run Frontend Only (Development)

```bash
npm run dev:frontend
```

This starts the Vite dev server at `http://localhost:5173`.

> Note: Without the Modal backend, the app will use a basic fallback summarization.

### Run Full Stack Locally (With Express Backend)

```bash
npm run dev
```

This starts the Express server at `http://localhost:5000`.

## üöÄ Deployment

### Step 1: Push to GitHub

1. **Create a new GitHub repository**

2. **Push your code:**
   ```bash
   git add .
   git commit -m "Initial commit - Note Summarizer"
   git branch -M main
   git remote add origin https://github.com/YOUR_USERNAME/note-summarizer.git
   git push -u origin main
   ```

### Step 2: Deploy Modal Backend

1. **Install Modal CLI:**
   ```bash
   pip install modal
   ```

2. **Authenticate with Modal:**
   ```bash
   modal setup
   ```

3. **Deploy the ML backend:**
   ```bash
   cd modal_backend
   modal deploy app.py
   ```

4. **Copy the endpoint URL** from the deployment output:
   ```
   ‚úì Created https://YOUR_USERNAME--note-summarizer-summarize-endpoint.modal.run
   ```

### Step 3: Connect GitHub to Vercel

1. **Go to [Vercel Dashboard](https://vercel.com/dashboard)**

2. **Click "Add New..." ‚Üí "Project"**

3. **Import your GitHub repository:**
   - Select "Import Git Repository"
   - Choose your `note-summarizer` repository
   - Click "Import"

4. **Configure the project:**
   - **Framework Preset**: Other
   - **Build Command**: `npm run build:vercel`
   - **Output Directory**: `dist`
   - **Install Command**: `npm install`

5. **Add Environment Variables:**
   - Click "Environment Variables"
   - Add: `MODAL_ENDPOINT` = `https://YOUR_USERNAME--note-summarizer-summarize-endpoint.modal.run`

6. **Click "Deploy"**

### Automatic Deployments

Once connected, Vercel will automatically deploy:
- ‚úÖ Every push to `main` ‚Üí Production deployment
- ‚úÖ Every pull request ‚Üí Preview deployment

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `MODAL_ENDPOINT` | URL of the Modal summarization endpoint | Yes (for ML summarization) |

## üìù API Endpoints

### POST /api/summarize

Summarizes the provided document content.

**Request Body:**
```json
{
  "content": "The text content to summarize...",
  "fileName": "document.txt",
  "chunkLength": 500,
  "overlapLength": 50
}
```

**Response:**
```json
{
  "id": "uuid",
  "fileName": "document.txt",
  "originalWordCount": 1500,
  "summaryText": "The generated summary...",
  "chunkLength": 500,
  "overlapLength": 50,
  "createdAt": "2024-01-01T00:00:00.000Z"
}
```

### GET /api/health

Health check endpoint.

**Response:**
```json
{
  "status": "ok",
  "timestamp": "2024-01-01T00:00:00.000Z"
}
```

## üß™ Testing

1. Visit your deployed URL or `http://localhost:5173` (local)
2. Upload a text file (or PDF/DOCX)
3. Adjust chunk and overlap parameters if desired
4. Click "Generate Summary"
5. Wait for processing and view results
6. Download or copy the summary

## üîß Configuration

### Summarization Parameters

| Parameter | Range | Default | Description |
|-----------|-------|---------|-------------|
| Chunk Length | 100-1000 | 500 | Words per chunk for processing |
| Overlap Length | 0-500 | 50 | Overlapping words between chunks |

### Modal GPU Options

The Modal backend uses a T4 GPU by default. You can modify `modal_backend/app.py` to use different GPU types:

```python
@app.cls(
    gpu="A10G",  # Options: T4, A10G, A100, H100
    container_idle_timeout=300,
)
```

## üêõ Troubleshooting

### Modal deployment fails
- Ensure you're authenticated: `modal setup`
- Check Python version compatibility (3.11 recommended)

### Vercel build fails
- Check the build logs in Vercel dashboard
- Ensure TypeScript compiles: `npm run check`

### Summarization returns fallback text
- Check if `MODAL_ENDPOINT` is set correctly in Vercel Environment Variables
- Verify Modal deployment is running: visit the Modal dashboard

### First request is slow
- The first request triggers model loading (~30s)
- Subsequent requests are much faster (warm container)

## üìÑ License

MIT
